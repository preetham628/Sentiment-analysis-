{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7abe9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65092abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['sentiment','id','date','query_string','user','text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abe294cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\pc\\Desktop\\training.1600000.processed.noemoticon.csv\",header=None, names=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc0acd22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query_string</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment          id                          date query_string  \\\n",
       "0          0  1467810369  Mon Apr 06 22:19:45 PDT 2009     NO_QUERY   \n",
       "1          0  1467810672  Mon Apr 06 22:19:49 PDT 2009     NO_QUERY   \n",
       "2          0  1467810917  Mon Apr 06 22:19:53 PDT 2009     NO_QUERY   \n",
       "3          0  1467811184  Mon Apr 06 22:19:57 PDT 2009     NO_QUERY   \n",
       "4          0  1467811193  Mon Apr 06 22:19:57 PDT 2009     NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c19fdc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1600000 entries, 0 to 1599999\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count    Dtype \n",
      "---  ------        --------------    ----- \n",
      " 0   sentiment     1600000 non-null  int64 \n",
      " 1   id            1600000 non-null  int64 \n",
      " 2   date          1600000 non-null  object\n",
      " 3   query_string  1600000 non-null  object\n",
      " 4   user          1600000 non-null  object\n",
      " 5   text          1600000 non-null  object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 73.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be3823d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    800000\n",
       "4    800000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8e42cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NO_QUERY    1600000\n",
       "Name: query_string, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query_string.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10a5e617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NO_QUERY    1600000\n",
       "Name: query_string, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query_string.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4e0cca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['id','date','query_string','user'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "862fcf9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text\n",
       "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1          0  is upset that he can't update his Facebook by ...\n",
       "2          0  @Kenichan I dived many times for the ball. Man...\n",
       "3          0    my whole body feels itchy and like its on fire \n",
       "4          0  @nationwideclass no, it's not behaving at all...."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1dade0f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>Need a hug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>@LOLTrish hey  long time no see! Yes.. Rains a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>@Tatiana_K nope they didn't have it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>@twittera que me muera ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text\n",
       "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1          0  is upset that he can't update his Facebook by ...\n",
       "2          0  @Kenichan I dived many times for the ball. Man...\n",
       "3          0    my whole body feels itchy and like its on fire \n",
       "4          0  @nationwideclass no, it's not behaving at all....\n",
       "5          0                      @Kwesidei not the whole crew \n",
       "6          0                                        Need a hug \n",
       "7          0  @LOLTrish hey  long time no see! Yes.. Rains a...\n",
       "8          0               @Tatiana_K nope they didn't have it \n",
       "9          0                          @twittera que me muera ? "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.sentiment == 0].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6390da02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>800000</th>\n",
       "      <td>4</td>\n",
       "      <td>I LOVE @Health4UandPets u guys r the best!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800001</th>\n",
       "      <td>4</td>\n",
       "      <td>im meeting up with one of my besties tonight! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800002</th>\n",
       "      <td>4</td>\n",
       "      <td>@DaRealSunisaKim Thanks for the Twitter add, S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800003</th>\n",
       "      <td>4</td>\n",
       "      <td>Being sick can be really cheap when it hurts t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800004</th>\n",
       "      <td>4</td>\n",
       "      <td>@LovesBrooklyn2 he has that effect on everyone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800005</th>\n",
       "      <td>4</td>\n",
       "      <td>@ProductOfFear You can tell him that I just bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800006</th>\n",
       "      <td>4</td>\n",
       "      <td>@r_keith_hill Thans for your response. Ihad al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800007</th>\n",
       "      <td>4</td>\n",
       "      <td>@KeepinUpWKris I am so jealous, hope you had a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800008</th>\n",
       "      <td>4</td>\n",
       "      <td>@tommcfly ah, congrats mr fletcher for finally...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800009</th>\n",
       "      <td>4</td>\n",
       "      <td>@e4VoIP I RESPONDED  Stupid cat is helping me ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentiment                                               text\n",
       "800000          4       I LOVE @Health4UandPets u guys r the best!! \n",
       "800001          4  im meeting up with one of my besties tonight! ...\n",
       "800002          4  @DaRealSunisaKim Thanks for the Twitter add, S...\n",
       "800003          4  Being sick can be really cheap when it hurts t...\n",
       "800004          4    @LovesBrooklyn2 he has that effect on everyone \n",
       "800005          4  @ProductOfFear You can tell him that I just bu...\n",
       "800006          4  @r_keith_hill Thans for your response. Ihad al...\n",
       "800007          4  @KeepinUpWKris I am so jealous, hope you had a...\n",
       "800008          4  @tommcfly ah, congrats mr fletcher for finally...\n",
       "800009          4  @e4VoIP I RESPONDED  Stupid cat is helping me ..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.sentiment == 4].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9df2fcce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([     0,      1,      2,      3,      4,      5,      6,      7,\n",
       "                 8,      9,\n",
       "            ...\n",
       "            799990, 799991, 799992, 799993, 799994, 799995, 799996, 799997,\n",
       "            799998, 799999],\n",
       "           dtype='int64', length=800000)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.sentiment == 0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a58230b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 800000,  800001,  800002,  800003,  800004,  800005,  800006,\n",
       "             800007,  800008,  800009,\n",
       "            ...\n",
       "            1599990, 1599991, 1599992, 1599993, 1599994, 1599995, 1599996,\n",
       "            1599997, 1599998, 1599999],\n",
       "           dtype='int64', length=800000)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.sentiment == 4].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf841f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = df['sentiment'].map({0: 0, 4: 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b899c6c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    800000\n",
       "1    800000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1dd409d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pre_clean_len'] = [len(t) for t in df.text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1351e8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_shape': (1600000, 3),\n",
      " 'pre_clean_len': {'description': 'Length of the tweet before cleaning',\n",
      "                   'type': dtype('int64')},\n",
      " 'sentiment': {'description': 'sentiment class - 0:negative, 1:positive',\n",
      "               'type': dtype('int64')},\n",
      " 'text': {'description': 'tweet text', 'type': dtype('O')}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "data_dict = {\n",
    "    'sentiment':{\n",
    "        'type':df.sentiment.dtype,\n",
    "        'description':'sentiment class - 0:negative, 1:positive'\n",
    "    },\n",
    "    'text':{\n",
    "        'type':df.text.dtype,\n",
    "        'description':'tweet text'\n",
    "    },\n",
    "    'pre_clean_len':{\n",
    "        'type':df.pre_clean_len.dtype,\n",
    "        'description':'Length of the tweet before cleaning'\n",
    "    },\n",
    "    'dataset_shape':df.shape\n",
    "}\n",
    "\n",
    "pprint(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7a2c7fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mad tired today... Callin it in early tonight  nighty night twittas'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text[289]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "480cd38f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Not Fun &amp; Furious? The new mantra for the Bay 2 Breakers? It was getting 2 rambunctious;the city overreacted &amp; clamped down '"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "re.sub(r'@[A-Za-z0-9]+','',df.text[343])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d32ba00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tok = WordPunctTokenizer()\n",
    "import lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22ad81dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pat1 = r'@[A-Za-z0-9]+'\n",
    "pat2 = r'https?://[A-Za-z0-9./]+'\n",
    "combined_pat = r'|'.join((pat1, pat2))\n",
    "\n",
    "def tweet_cleaner(text):\n",
    "    soup = BeautifulSoup(text,\"html.parser\")\n",
    "    souped = soup.get_text()\n",
    "    stripped = re.sub(combined_pat, '', souped)\n",
    "    try:\n",
    "        clean = stripped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n",
    "    except:\n",
    "        clean = stripped\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", clean)\n",
    "    lower_case = letters_only.lower()\n",
    "\n",
    "    words = tok.tokenize(lower_case)\n",
    "    return (\" \".join(words)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b27420fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = df.text[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "197e9ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = []\n",
    "for t in testing:\n",
    "    test_result.append(tweet_cleaner(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "223ff1f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['awww that s a bummer you shoulda got david carr of third day to do it d',\n",
       " 'is upset that he can t update his facebook by texting it and might cry as a result school today also blah',\n",
       " 'i dived many times for the ball managed to save the rest go out of bounds',\n",
       " 'my whole body feels itchy and like its on fire',\n",
       " 'no it s not behaving at all i m mad why am i here because i can t see you all over there',\n",
       " 'not the whole crew',\n",
       " 'need a hug',\n",
       " 'hey long time no see yes rains a bit only a bit lol i m fine thanks how s you',\n",
       " 'k nope they didn t have it',\n",
       " 'que me muera',\n",
       " 'spring break in plain city it s snowing',\n",
       " 'i just re pierced my ears',\n",
       " 'i couldn t bear to watch it and i thought the ua loss was embarrassing',\n",
       " 'it it counts idk why i did either you never talk to me anymore',\n",
       " 'i would ve been the first but i didn t have a gun not really though zac snyder s just a doucheclown',\n",
       " 'i wish i got to watch it with you i miss you and how was the premiere',\n",
       " 'hollis death scene will hurt me severely to watch on film wry is directors cut not out now',\n",
       " 'about to file taxes',\n",
       " 'ahh ive always wanted to see rent love the soundtrack',\n",
       " 'oh dear were you drinking out of the forgotten table drinks',\n",
       " 'i was out most of the day so didn t get much done',\n",
       " 'one of my friend called me and asked to meet with her at mid valley today but i ve no time sigh',\n",
       " 'barista i baked you a cake but i ated it',\n",
       " 'this week is not going as i had hoped',\n",
       " 'blagh class at tomorrow',\n",
       " 'i hate when i have to call and wake people up',\n",
       " 'just going to cry myself to sleep after watching marley and me',\n",
       " 'im sad now miss lilly',\n",
       " 'ooooh lol that leslie and ok i won t do it again so leslie won t get mad again',\n",
       " 'meh almost lover is the exception this track gets me depressed every time',\n",
       " 'some hacked my account on aim now i have to make a new one',\n",
       " 'i want to go to promote gear and groove but unfornately no ride there i may b going to the one in anaheim in may though',\n",
       " 'thought sleeping in was an option tomorrow but realizing that it now is not evaluations in the morning and work in the afternoon',\n",
       " 'awe i love you too am here i miss you',\n",
       " 'i cry my asian eyes to sleep at night',\n",
       " 'ok i m sick and spent an hour sitting in the shower cause i was too sick to stand and held back the puke like a champ bed now',\n",
       " 'ill tell ya the story later not a good day and ill be workin for like three more hours',\n",
       " 'sorry bed time came here gmt',\n",
       " 'i don t either its depressing i don t think i even want to know about the kids in suitcases',\n",
       " 'bed class work gym or then class another day that s gonna fly by i miss my girlfriend',\n",
       " 'really don t feel like getting up today but got to study to for tomorrows practical exam',\n",
       " 'he s the reason for the teardrops on my guitar the only one who has enough of me to break my heart',\n",
       " 'sad sad sad i don t know why but i hate this feeling i wanna sleep and i still can t',\n",
       " 'awww i soo wish i was there to see you finally comfortable im sad that i missed it',\n",
       " 'falling asleep just heard about that tracy girl s body being found how sad my heart breaks for that family',\n",
       " 'yay i m happy for you with your job but that also means less time for me and you',\n",
       " 'just checked my user timeline on my blackberry it looks like the twanking is still happening are ppl still having probs w bgs and uids',\n",
       " 'oh man was ironing s fave top to wear to a meeting burnt it',\n",
       " 'is strangely sad about lilo and samro breaking up',\n",
       " 'oh i m so sorry i didn t think about that before retweeting',\n",
       " 'broadband plan a massive broken promise via www diigo com tautao still waiting for broadband we are',\n",
       " 'wow tons of replies from you may have to unfollow so i can see my friends tweets you re scrolling the feed a lot',\n",
       " 'our duck and chicken are taking wayyy too long to hatch',\n",
       " 'put vacation photos online a few yrs ago pc crashed and now i forget the name of the site',\n",
       " 'i need a hug',\n",
       " 'not sure what they are only that they are pos as much as i want to i dont think can trade away company assets sorry andy',\n",
       " 'i hate when that happens',\n",
       " 'i have a sad feeling that dallas is not going to show up i gotta say though you d think more shows would use music from the game mmm',\n",
       " 'ugh degrees tomorrow',\n",
       " 'where did u move to i thought u were already in sd hmmm random u found me glad to hear yer doing well',\n",
       " 'i miss my ps it s out of commission wutcha playing have you copped blood on the sand',\n",
       " 'just leaving the parking lot of work',\n",
       " 'the life is cool but not for me',\n",
       " 'sadly though i ve never gotten to experience the post coitus cigarette before and now i never will',\n",
       " 'i had such a nice day too bad the rain comes in tomorrow at am',\n",
       " 'too bad i won t be around i lost my job and can t even pay my phone bill lmao aw shucks',\n",
       " 'damm back to school tomorrow',\n",
       " 'mo jobs no money how in the hell is min wage here f n clams an hour',\n",
       " 'not forever see you soon',\n",
       " 'algonquin agreed i saw the failwhale allllll day today',\n",
       " 'oh haha dude i dont really look at em unless someone says hey i added you sorry i m so terrible at that i need a pop up',\n",
       " 'i m sure you re right i need to start working out with you and the nikster or jared at least',\n",
       " 'i really hate how people diss my bands trace is clearly not ugly',\n",
       " 'gym attire today was puma singlet adidas shorts and black business socks and leather shoes lucky did not run into any cute girls',\n",
       " 'why won t you show my location',\n",
       " 'no picnic my phone smells like citrus',\n",
       " 'my donkey is sensitive about such comments nevertheless he d and me d be glad to see your mug asap charger is still awol',\n",
       " 'no new csi tonight fml',\n",
       " 'i think my arms are sore from tennis',\n",
       " 'wonders why someone that u like so much can make you so unhappy in a split seccond depressed',\n",
       " 'sleep soon i just hate saying bye and see you tomorrow for the night',\n",
       " 'just got ur newsletter those fares really are unbelievable shame i already booked and paid for mine',\n",
       " 'missin the boo',\n",
       " 'me too itm',\n",
       " 'damn i don t have any chalk my chalkboard is useless',\n",
       " 'had a blast at the getty villa but hates that she s had a sore throat all day it s just getting worse too',\n",
       " 'hey missed ya at the meeting sup mama',\n",
       " 'my tummy hurts i wonder if the hypnosis has anything to do with it if so it s working i get it stop smoking',\n",
       " 'why is it always the fat ones',\n",
       " 'sorry babe my fam annoys me too thankfully they re asleep right now muahaha evil laugh',\n",
       " 'i should have paid more attention when we covered photoshop in my webpage design class in undergrad',\n",
       " 'wednesday my b day don t know what do',\n",
       " 'poor cameron the hills',\n",
       " 'pray for me please the ex is threatening to start sh at my our babies st birthday party what a jerk and i still have a headache',\n",
       " 'hmm do u really enjoy being with him if the problems are too constants u should think things more find someone ulike',\n",
       " 'strider is a sick little puppy',\n",
       " 'so rylee grace wana go steve s party or not sadly since its easter i wnt b able do much but ohh well',\n",
       " 'hey i actually won one of my bracket pools too bad it wasn t the one for money',\n",
       " 'you don t follow me either and i work for you',\n",
       " 'a bad nite for the favorite teams astros and spartans lose the nite out with t w was good',\n",
       " 'body of missing northern calif girl found police have found the remains of a missing northern california girl',\n",
       " 'i hope they will increase the capacity fast yesterday was such a pain got the fail whale times in hours',\n",
       " 'behind on my classes for work',\n",
       " 'watching house',\n",
       " 'remember my bum leg strikes back this time its serious',\n",
       " 'cool i will their are all kinds of complaints about this laptop online about overheating but no recalls',\n",
       " 'emily will be glad when mommy is done training at her new job she misses her',\n",
       " 'would rather the first party send bad messages than the rd party send mixed ones sophmore year all over again',\n",
       " 'it s overrated',\n",
       " 'q i know i heard it this afternoon and wondered the same thing moscow is so behind the times',\n",
       " 'laying in bed with no voice',\n",
       " 'i m sooo sad they killed off kutner on house whyyyyyyyy',\n",
       " 'sorry tell them mea culpa from me and that i really am sorry',\n",
       " 'it didn t make any sense to me the suicide thing i refuse to believe that that is actually what happened',\n",
       " 'hope your ok',\n",
       " 'damn the grind is inspirational and saddening at the same time don t want you to stop cuz i like what u do much love',\n",
       " 'yeah aw but i know i wudnt stand a chance',\n",
       " 'ugh cant sleep its am',\n",
       " 'hanging in crooners wanna sing can t sucks',\n",
       " 'sc aaw i miss ya all too im leaving to bh tomorrow morning i think aww i wanna go to the beach w u girls',\n",
       " 'is pissed off that there s no asba s for a radio station',\n",
       " 'wednesday my b day n don t know what do',\n",
       " 'i know my life has been flipped upside down when i just thought in my head that some ramen sounds good',\n",
       " 'i am in pain my back and sides hurt not to mention crying is made of fail',\n",
       " 'late night snack glass of oj b c i m down with the sickness then back to sleep ugh i hate getting sick',\n",
       " 'but but but i m not a big fan on camilla belle',\n",
       " 'wah i can t see clip must be el stupido work filters can t wait till i get a puter something else blame ex he broke mine',\n",
       " 'this week just seems to get longer and longer in terms of how much i need to do and how much i m actually going to get done',\n",
       " 'i m so cold',\n",
       " 'ehhh don t weather s gonna take a turn for the ugly tomorrow',\n",
       " 'haha its so cooooold in the d and no but you should still go to the show they do some incredible stuff',\n",
       " 'hoping the tummy rumbles go away soon',\n",
       " 'no no notice they told me i d be working tomorrow and then i called the agency to follow up and they said it was over',\n",
       " 'almost bedtime',\n",
       " 'i m missing you babe but as long as your alive i m happy yawwwnn i m tired my love imma try to sleep hopefully you had a headstart',\n",
       " 'agh snow',\n",
       " 'i miss kenny powers',\n",
       " 'thank you for letting people know but now i m sad that the direct message i got wasn t actually from bridget',\n",
       " 'and india missed out its th test victory n th consecutive win without a loss',\n",
       " 'i guess that s a no then',\n",
       " 'sadly is going to bed',\n",
       " 'shame to hear this stephan',\n",
       " 'hey i m leavin in the morning',\n",
       " 'was intending to finish editing my page novel manuscript tonight but that will probably not happen and only pages are left',\n",
       " 'laid around too much today now my head hurts',\n",
       " 'i still haven t read the th th princess diaries saving francesca made me cry at the end hmm those are easy books',\n",
       " 'my nokia died',\n",
       " 'my mom might have breast cancer won t find out anything for like a week i m so worried',\n",
       " 'going to sleep hoping tomorrow is a better day',\n",
       " 'lol wish they understood daylight savings has ended though and breakfast is an hour later they keep waking the kids up too',\n",
       " 'that is lame',\n",
       " 'i don t understand i really don t',\n",
       " 'heroes just isn t doing it for me this season',\n",
       " 'living not downtown sure isn t much fun',\n",
       " 'not calorie wise i wish junk food was calorie free i ate a thing of sour skittles and a big ass cherry coke',\n",
       " 'man work is hard',\n",
       " 'getting sick time for some hot tea studying and then sleeeep',\n",
       " 'getting eyebrows waxed more pain',\n",
       " 'no phantasy star yesterday going to work',\n",
       " 'oh just got all my macheist apps sweet didn t get the espresso serial no though although they said they sent it oh well',\n",
       " 'picked mich st to win it all from the get go was feeling pretty good about that pick all the way up until tonight a s lost too',\n",
       " 'is alone downstairs working',\n",
       " 'i feel bad for doing it',\n",
       " 'is it just me or she hates anoop i mean seriously she s kinda mean to him',\n",
       " 'yes sprint has g only in baltimore and chicago so far',\n",
       " 'i m stuck awake in the middle of the night for the second day in a row and i felt terrible yesterday',\n",
       " 'thanks for bursting my bubble',\n",
       " 'going to school soon can t find anything to wear gosh it s so hard',\n",
       " 'i was serious lol',\n",
       " 'i had on my page for sooooo long until it got deleted sad day in history',\n",
       " 'crazy wind today no birding',\n",
       " 'currently at work',\n",
       " 'grrr my ipods acting weird too jai ho and thinking of you aren t playing the full songs ughh',\n",
       " 'send me the dvd cos i have missed out on heaps not happy about that',\n",
       " 'i don t see the big deal with this website',\n",
       " 'i m so sorry you re having to go through this again therapyfail',\n",
       " 'far too out of the way for rail any other tips',\n",
       " 'i m not still up i swear why do i keep losing gaining losing gaining tweeps so heart wrenching',\n",
       " 'today i realized i am too good at hiding things even i can t find it',\n",
       " 'staying at a friends house house sitting neighbors are so loud having a party',\n",
       " 'danny im upset that i wasnt here to watch the live chat i was in a car for hours on a trip im soooo upset',\n",
       " 'check out my mug obscura blogspot com',\n",
       " 'borders closed at',\n",
       " 'downloading nin s new album the slip when the hell did this come out i m so behind the times these days',\n",
       " 'just woke up an already have written some e mail i ve to go early at university today as i have to teach at am',\n",
       " 'is watching the hill and its making me sad',\n",
       " 'so many channels yet so so boring lazy day again may have to find a hobby',\n",
       " 'i miss my buddy ill be in ny on the th',\n",
       " 'love the french i tell people here in the south i m qtr french and they snarl at me french are beautiful people',\n",
       " 'opps as i said i still got one day remain and now problem come',\n",
       " 'i activated my selfcontrol block early meaning i can t check out the new qc regularizing my internal clock is might be difficult fb',\n",
       " 'oh no',\n",
       " 'spencer is not a good guy',\n",
       " 'what about reese dying on ttsc and season finale next week boring madame president is a crazy woman',\n",
       " 'i hate the limited letters too hope you and the guys are fine i pray for my dog she s not well',\n",
       " 'didn t get shit done today i m so screwed',\n",
       " 'wanttss to go out',\n",
       " 'is not going to sleep tonite',\n",
       " 'too worried and tired to post tonight',\n",
       " 'couldn t get shit done today i m so screwed',\n",
       " 'job interview in cardiff today wish me luck got about hours sleep',\n",
       " 'your show is whack way worse than whack it s wiggety whack',\n",
       " 'i really don t think people choose to be that way but i think he chose not to accept my family s help he might be dead by now',\n",
       " 'you re going to kill me but i ve not seen ds i ve been waiting till i can do it in one solid week sitting',\n",
       " 'i think ur right hahaha hrs now',\n",
       " 'i hate to see the spartans so sad',\n",
       " 'my mind and body are severely protesting this getting up thing had nightmares to boot',\n",
       " 'i m goin to follow u since u didn t lol go angels',\n",
       " '',\n",
       " 'i think i want to read some books but the library doesn t have them',\n",
       " 'my nap was interrupted so many times today going out for japanese with the rents again',\n",
       " 'kind of longs for the bus that shows up at the end of ghost world right now ugh',\n",
       " 'but this is canada canada is weird we re supposed to get snow through wednesday ugh',\n",
       " 'awwh babs you look so sad underneith that shop entrance of yesterday s musik o i like the look of the new transformer movie',\n",
       " 'sad that the feet of my macbook just fell off',\n",
       " 'i m gonna get up late tomorrow and it s am here i gonna get tipsy by my lonesome that s that s just sad',\n",
       " 'i m sweating my forthcoming trip to e if i can t find someone to crash with while i m out there i may be screwed',\n",
       " 'has now gotten somebody to read his tweets but cant get them to make an account',\n",
       " 'omgawd i couldnt handle my cat being in heat all the time d d',\n",
       " 'i hope i can make it to the auburn show but its not looking good for me',\n",
       " 'henrie thats people mag haha i couldnt fit it all in i dont think those pictures ever made it in the magazine tho haha',\n",
       " 'congrats i totally forgot to submit photos',\n",
       " 'awww good luck paula please don t work too hard but i hope you have fun your new album is gonna be amazing xxx',\n",
       " 'now your leaving me gets sad',\n",
       " 'i miss you twitter my phone broke now i m using a stupid nokia phone ughhh i miss my advance phone',\n",
       " 'shooting outside my house o not kidding so scared',\n",
       " 'tuesday ll start with reflection n then a lecture in stress reducing techniques that sure might become very useful for us accompaniers',\n",
       " 'what tragedy and disaster in the news this week',\n",
       " 'yes yes still trying to find a picture that will upload correclty',\n",
       " 'why oh why was the red sox game rained out i was so looking forward to opening day',\n",
       " 'i still can t find my keys',\n",
       " 'i know right i dunno what is going on with twitter',\n",
       " 'might be getting a sore throat again',\n",
       " 'my home town my mammy called all depressd pls explain y a parent let their yr old child walk alone hello its',\n",
       " 'i think i need to find better anti depressants i think this paxil wellbutrin combo is losing its efficacy',\n",
       " 'restaurant called woodntap has competitive eating tourney round tourney time we place nd',\n",
       " 'is in the bathroom wake up lakin',\n",
       " 'i want tacos and margarhitas telll gay i say hello',\n",
       " 'im lonely keep me company female california',\n",
       " 'bad day at the betfair office',\n",
       " 'i miss him can t wait to celebrate the tar heel win this weekend though',\n",
       " 'i m really cold i don t want to go to sleep yet but there s nothing to do',\n",
       " 'is this it u its officially over me this go round',\n",
       " 'monkeys i just found out you my twin and you wont even write back i m heartbroken',\n",
       " 'om aww i know i felt like that yesterday at work',\n",
       " 'treaty isn t defined',\n",
       " 'missed brent at praise band no fun to not have the your lead guitarist pout',\n",
       " 'poor john this is what happens when you play with fruit and a microwave seriously though have you seen a doctor xxx',\n",
       " 'missing my bff watching home and away it reminds me of her and me we it shout out to u courts',\n",
       " '',\n",
       " 'new video card is doa',\n",
       " 'feeling lost naked and confused jk sort of no iphone for me',\n",
       " 'damn i am so late at filling this appraisal form people have almost sent it i was so occupied in work',\n",
       " 'missed brent at praise band no fun to not have your lead guitarist pout',\n",
       " 'i think to much on the past i cant change it i deserved so much more then wat i got but why am i still thinking about him gah',\n",
       " 'has lost his ring it s no where to be seen',\n",
       " 'ooooooh sealclap see i download shitloads of zip folders off chan i have no internet moneys fuck yeah alicia mikey',\n",
       " 'is still nursing my nile but glad he is feeling better i hate when my baby is sick',\n",
       " 'is fucked to go back to ic',\n",
       " 'yoyoyo my internet has been rude tonight it just reconnected and i m about to go to bed',\n",
       " 'well i have uni stuff and netball but after netbal if i ve done uni stuff we can',\n",
       " 'me too i is poor',\n",
       " 'help me forget th april th july',\n",
       " 'dierks bentley is comin to columbus oh i wanna go so bad',\n",
       " 'i have to take my sidekick back',\n",
       " 'congrats i m totally jealous only wish my xm was working',\n",
       " 'gr t my face is very itchy',\n",
       " 'poor socks luvvvvv the golden retriever i want one sighhhh',\n",
       " 'i just saw that they found that tracy girl in a piece of luggage how fucking terrible',\n",
       " 'aaaaand the nausea is back',\n",
       " 'ooh i m excited and not even going be there long love youtube',\n",
       " 'spent hour to reach to axis bank only to find out today is holiday for mahavir jayanti contd',\n",
       " 'i agree the jobros dont update theres very often',\n",
       " 'it is hilarious and i linked the clip from lj some time ago but when i went back just now it was a dead link',\n",
       " 'oooooooo who with im not neither but thats because i need to study',\n",
       " 'haven t tweeted nearly all day posted my website tonight hopefully that goes well night time',\n",
       " 'i miss bentley',\n",
       " 'seriously needs to finish these job applications',\n",
       " 'my son vincas is sick so i stay at home just three tense days at work and i am back on holiday with kids',\n",
       " 'whinging my client boss don t understand english well rewrote some text unreadable it s written by v good writer reviewed correctly',\n",
       " 'i don t want him to ever punch me',\n",
       " 'sooo sick of the snow ughh',\n",
       " 'nemesis',\n",
       " 'it doesn t work your fan is upset',\n",
       " 'i would like to apologize for the repeated video games live related tweets i am going to have a stern discussion with koodo soon stern',\n",
       " 'but i cant figure out how to get there back pay for a hotel etc',\n",
       " 'fml so much for seniority bc of technological ineptness i now have to register for classes again',\n",
       " 'feels like she slept the day away not looking forward to any more bouts with my gallbladder at least i have pills now for the pain',\n",
       " 'but what i really want is my old bass back',\n",
       " 'mad tired today callin it in early tonight nighty night twittas',\n",
       " 'take it easy and be good to you',\n",
       " 'i m afraid i had bad code',\n",
       " 'think i m going to bed goodniight i hate this',\n",
       " 'i m here friend and i love you',\n",
       " 'all this time you didn t notice i was gone just needed db is it',\n",
       " 'is in the bathroom and i have to pee',\n",
       " 'but i wanted a margarita too',\n",
       " 'yup night workouts r the worst but unfortunetly my work schedule only allows me to go at night its tough',\n",
       " 'just called hillsong again they said they couldn t tell me where i was on the waiting list i don t know if it s looking so good',\n",
       " 'has g of milky bar left and around ml of coke']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "922f01d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = [0,400000,800000,1200000,1600000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3f87d8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the tweets...\n",
      "\n",
      "Tweets 10000 of 400000 has been processed\n",
      "Tweets 20000 of 400000 has been processed\n",
      "Tweets 30000 of 400000 has been processed\n",
      "Tweets 40000 of 400000 has been processed\n",
      "Tweets 50000 of 400000 has been processed\n",
      "Tweets 60000 of 400000 has been processed\n",
      "Tweets 70000 of 400000 has been processed\n",
      "Tweets 80000 of 400000 has been processed\n",
      "Tweets 90000 of 400000 has been processed\n",
      "Tweets 100000 of 400000 has been processed\n",
      "Tweets 110000 of 400000 has been processed\n",
      "Tweets 120000 of 400000 has been processed\n",
      "Tweets 130000 of 400000 has been processed\n",
      "Tweets 140000 of 400000 has been processed\n",
      "Tweets 150000 of 400000 has been processed\n",
      "Tweets 160000 of 400000 has been processed\n",
      "Tweets 170000 of 400000 has been processed\n",
      "Tweets 180000 of 400000 has been processed\n",
      "Tweets 190000 of 400000 has been processed\n",
      "Tweets 200000 of 400000 has been processed\n",
      "Tweets 210000 of 400000 has been processed\n",
      "Tweets 220000 of 400000 has been processed\n",
      "Tweets 230000 of 400000 has been processed\n",
      "Tweets 240000 of 400000 has been processed\n",
      "Tweets 250000 of 400000 has been processed\n",
      "Tweets 260000 of 400000 has been processed\n",
      "Tweets 270000 of 400000 has been processed\n",
      "Tweets 280000 of 400000 has been processed\n",
      "Tweets 290000 of 400000 has been processed\n",
      "Tweets 300000 of 400000 has been processed\n",
      "Tweets 310000 of 400000 has been processed\n",
      "Tweets 320000 of 400000 has been processed\n",
      "Tweets 330000 of 400000 has been processed\n",
      "Tweets 340000 of 400000 has been processed\n",
      "Tweets 350000 of 400000 has been processed\n",
      "Tweets 360000 of 400000 has been processed\n",
      "Tweets 370000 of 400000 has been processed\n",
      "Tweets 380000 of 400000 has been processed\n",
      "Tweets 390000 of 400000 has been processed\n",
      "Tweets 400000 of 400000 has been processed\n",
      "Wall time: 1min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Cleaning and parsing the tweets...\\n\")\n",
    "clean_tweet_texts = []\n",
    "for i in range(nums[0],nums[1]):\n",
    "    if( (i+1)%10000 == 0 ):\n",
    "        print(\"Tweets %d of %d has been processed\" % ( i+1, nums[1] ))                                                                    \n",
    "    clean_tweet_texts.append(tweet_cleaner(df['text'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2f47dd1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_tweet_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4ce43d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the tweets...\n",
      "\n",
      "Tweets 410000 of 800000 has been processed\n",
      "Tweets 420000 of 800000 has been processed\n",
      "Tweets 430000 of 800000 has been processed\n",
      "Tweets 440000 of 800000 has been processed\n",
      "Tweets 450000 of 800000 has been processed\n",
      "Tweets 460000 of 800000 has been processed\n",
      "Tweets 470000 of 800000 has been processed\n",
      "Tweets 480000 of 800000 has been processed\n",
      "Tweets 490000 of 800000 has been processed\n",
      "Tweets 500000 of 800000 has been processed\n",
      "Tweets 510000 of 800000 has been processed\n",
      "Tweets 520000 of 800000 has been processed\n",
      "Tweets 530000 of 800000 has been processed\n",
      "Tweets 540000 of 800000 has been processed\n",
      "Tweets 550000 of 800000 has been processed\n",
      "Tweets 560000 of 800000 has been processed\n",
      "Tweets 570000 of 800000 has been processed\n",
      "Tweets 580000 of 800000 has been processed\n",
      "Tweets 590000 of 800000 has been processed\n",
      "Tweets 600000 of 800000 has been processed\n",
      "Tweets 610000 of 800000 has been processed\n",
      "Tweets 620000 of 800000 has been processed\n",
      "Tweets 630000 of 800000 has been processed\n",
      "Tweets 640000 of 800000 has been processed\n",
      "Tweets 650000 of 800000 has been processed\n",
      "Tweets 660000 of 800000 has been processed\n",
      "Tweets 670000 of 800000 has been processed\n",
      "Tweets 680000 of 800000 has been processed\n",
      "Tweets 690000 of 800000 has been processed\n",
      "Tweets 700000 of 800000 has been processed\n",
      "Tweets 710000 of 800000 has been processed\n",
      "Tweets 720000 of 800000 has been processed\n",
      "Tweets 730000 of 800000 has been processed\n",
      "Tweets 740000 of 800000 has been processed\n",
      "Tweets 750000 of 800000 has been processed\n",
      "Tweets 760000 of 800000 has been processed\n",
      "Tweets 770000 of 800000 has been processed\n",
      "Tweets 780000 of 800000 has been processed\n",
      "Tweets 790000 of 800000 has been processed\n",
      "Tweets 800000 of 800000 has been processed\n",
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Cleaning and parsing the tweets...\\n\")\n",
    "for i in range(nums[1],nums[2]):\n",
    "    if( (i+1)%10000 == 0 ):\n",
    "        print(\"Tweets %d of %d has been processed\" % ( i+1, nums[2] )  )                                                                  \n",
    "    clean_tweet_texts.append(tweet_cleaner(df['text'][i]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f5b667ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800000"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_tweet_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "22cd3f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the tweets...\n",
      "\n",
      "Tweets 810000 of 1200000 has been processed\n",
      "Tweets 820000 of 1200000 has been processed\n",
      "Tweets 830000 of 1200000 has been processed\n",
      "Tweets 840000 of 1200000 has been processed\n",
      "Tweets 850000 of 1200000 has been processed\n",
      "Tweets 860000 of 1200000 has been processed\n",
      "Tweets 870000 of 1200000 has been processed\n",
      "Tweets 880000 of 1200000 has been processed\n",
      "Tweets 890000 of 1200000 has been processed\n",
      "Tweets 900000 of 1200000 has been processed\n",
      "Tweets 910000 of 1200000 has been processed\n",
      "Tweets 920000 of 1200000 has been processed\n",
      "Tweets 930000 of 1200000 has been processed\n",
      "Tweets 940000 of 1200000 has been processed\n",
      "Tweets 950000 of 1200000 has been processed\n",
      "Tweets 960000 of 1200000 has been processed\n",
      "Tweets 970000 of 1200000 has been processed\n",
      "Tweets 980000 of 1200000 has been processed\n",
      "Tweets 990000 of 1200000 has been processed\n",
      "Tweets 1000000 of 1200000 has been processed\n",
      "Tweets 1010000 of 1200000 has been processed\n",
      "Tweets 1020000 of 1200000 has been processed\n",
      "Tweets 1030000 of 1200000 has been processed\n",
      "Tweets 1040000 of 1200000 has been processed\n",
      "Tweets 1050000 of 1200000 has been processed\n",
      "Tweets 1060000 of 1200000 has been processed\n",
      "Tweets 1070000 of 1200000 has been processed\n",
      "Tweets 1080000 of 1200000 has been processed\n",
      "Tweets 1090000 of 1200000 has been processed\n",
      "Tweets 1100000 of 1200000 has been processed\n",
      "Tweets 1110000 of 1200000 has been processed\n",
      "Tweets 1120000 of 1200000 has been processed\n",
      "Tweets 1130000 of 1200000 has been processed\n",
      "Tweets 1140000 of 1200000 has been processed\n",
      "Tweets 1150000 of 1200000 has been processed\n",
      "Tweets 1160000 of 1200000 has been processed\n",
      "Tweets 1170000 of 1200000 has been processed\n",
      "Tweets 1180000 of 1200000 has been processed\n",
      "Tweets 1190000 of 1200000 has been processed\n",
      "Tweets 1200000 of 1200000 has been processed\n",
      "Wall time: 1min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Cleaning and parsing the tweets...\\n\")\n",
    "for i in range(nums[2],nums[3]):\n",
    "    if( (i+1)%10000 == 0 ):\n",
    "        print(\"Tweets %d of %d has been processed\" % ( i+1, nums[3] ))                                                                  \n",
    "    clean_tweet_texts.append(tweet_cleaner(df['text'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ed7f2f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1200000"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_tweet_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c1cc5535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the tweets...\n",
      "\n",
      "Tweets 1210000 of 1600000 has been processed\n",
      "Tweets 1220000 of 1600000 has been processed\n",
      "Tweets 1230000 of 1600000 has been processed\n",
      "Tweets 1240000 of 1600000 has been processed\n",
      "Tweets 1250000 of 1600000 has been processed\n",
      "Tweets 1260000 of 1600000 has been processed\n",
      "Tweets 1270000 of 1600000 has been processed\n",
      "Tweets 1280000 of 1600000 has been processed\n",
      "Tweets 1290000 of 1600000 has been processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\anaconda3\\envs\\bd\\lib\\site-packages\\bs4\\__init__.py:332: MarkupResemblesLocatorWarning: \"E3 ON PLAYSTATION HOME IN ABOUT AN HOUR!!!!!!!!!! \\../  \\../\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets 1300000 of 1600000 has been processed\n",
      "Tweets 1310000 of 1600000 has been processed\n",
      "Tweets 1320000 of 1600000 has been processed\n",
      "Tweets 1330000 of 1600000 has been processed\n",
      "Tweets 1340000 of 1600000 has been processed\n",
      "Tweets 1350000 of 1600000 has been processed\n",
      "Tweets 1360000 of 1600000 has been processed\n",
      "Tweets 1370000 of 1600000 has been processed\n",
      "Tweets 1380000 of 1600000 has been processed\n",
      "Tweets 1390000 of 1600000 has been processed\n",
      "Tweets 1400000 of 1600000 has been processed\n",
      "Tweets 1410000 of 1600000 has been processed\n",
      "Tweets 1420000 of 1600000 has been processed\n",
      "Tweets 1430000 of 1600000 has been processed\n",
      "Tweets 1440000 of 1600000 has been processed\n",
      "Tweets 1450000 of 1600000 has been processed\n",
      "Tweets 1460000 of 1600000 has been processed\n",
      "Tweets 1470000 of 1600000 has been processed\n",
      "Tweets 1480000 of 1600000 has been processed\n",
      "Tweets 1490000 of 1600000 has been processed\n",
      "Tweets 1500000 of 1600000 has been processed\n",
      "Tweets 1510000 of 1600000 has been processed\n",
      "Tweets 1520000 of 1600000 has been processed\n",
      "Tweets 1530000 of 1600000 has been processed\n",
      "Tweets 1540000 of 1600000 has been processed\n",
      "Tweets 1550000 of 1600000 has been processed\n",
      "Tweets 1560000 of 1600000 has been processed\n",
      "Tweets 1570000 of 1600000 has been processed\n",
      "Tweets 1580000 of 1600000 has been processed\n",
      "Tweets 1590000 of 1600000 has been processed\n",
      "Tweets 1600000 of 1600000 has been processed\n",
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Cleaning and parsing the tweets...\\n\")\n",
    "for i in range(nums[3],nums[4]):\n",
    "    if( (i+1)%10000 == 0 ):\n",
    "        print(\"Tweets %d of %d has been processed\" % ( i+1, nums[4] ))                                                                   \n",
    "    clean_tweet_texts.append(tweet_cleaner(df['text'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "658fe302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600000"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_tweet_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fc8132b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>awww that s a bummer you shoulda got david car...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can t update his facebook by ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i dived many times for the ball managed to sav...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no it s not behaving at all i m mad why am i h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  awww that s a bummer you shoulda got david car...       0\n",
       "1  is upset that he can t update his facebook by ...       0\n",
       "2  i dived many times for the ball managed to sav...       0\n",
       "3     my whole body feels itchy and like its on fire       0\n",
       "4  no it s not behaving at all i m mad why am i h...       0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df = pd.DataFrame(clean_tweet_texts,columns=['text'])\n",
    "clean_df['target'] = df.sentiment\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3f651ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.to_csv('clean_tweet.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2c2b8940",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\anaconda3\\envs\\bd\\lib\\site-packages\\numpy\\lib\\arraysetops.py:583: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>awww that s a bummer you shoulda got david car...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can t update his facebook by ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i dived many times for the ball managed to sav...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no it s not behaving at all i m mad why am i h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  awww that s a bummer you shoulda got david car...       0\n",
       "1  is upset that he can t update his facebook by ...       0\n",
       "2  i dived many times for the ball managed to sav...       0\n",
       "3     my whole body feels itchy and like its on fire       0\n",
       "4  no it s not behaving at all i m mad why am i h...       0"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv = 'clean_tweet.csv'\n",
    "my_df = pd.read_csv(csv,index_col=0)\n",
    "my_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9794e29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting findspark\n",
      "  Downloading findspark-1.4.2-py2.py3-none-any.whl (4.2 kB)\n",
      "Installing collected packages: findspark\n",
      "Successfully installed findspark-1.4.2\n"
     ]
    }
   ],
   "source": [
    "!(pip install findspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cfe54659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "t=df.text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6d3c7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "result=[]\n",
    "result.append(tweet_cleaner(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca324d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i am a very enthusiastic about crypto i will always contribute and support about the arche project especially in building the arche community around the world']\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f272b119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i am a very enthusiastic about crypto i will a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  i am a very enthusiastic about crypto i will a..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_df = pd.DataFrame(result,columns=['text'])\n",
    "c_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e08a4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_df.to_csv(\"testtweet.csv\",encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e6e8702e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 8: expected 2 fields, saw 4\\nSkipping line 9: expected 2 fields, saw 4\\nSkipping line 12: expected 2 fields, saw 4\\n'\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(r\"OutputStreaming.csv\",error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c940dce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Impresive and great project. I trust this proj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @cryptomanran: Elon Musks irresponsible tw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @Teslacryptos: Our mission is to advance hu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @bmurphypointman: #business #businesses #bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @JuliansyahAsdar: @fire_protocol Great proj...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Impresive and great project. I trust this proj...\n",
       "1  RT @cryptomanran: Elon Musks irresponsible tw...\n",
       "2  RT @Teslacryptos: Our mission is to advance hu...\n",
       "3  RT @bmurphypointman: #business #businesses #bu...\n",
       "4  RT @JuliansyahAsdar: @fire_protocol Great proj..."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "92a9ba4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedC=df1[[\"text\"]]\n",
    "new_df = selectedC.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f9e440d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Impresive and great project. I trust this proj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @cryptomanran: Elon Musks irresponsible tw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @Teslacryptos: Our mission is to advance hu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @bmurphypointman: #business #businesses #bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @JuliansyahAsdar: @fire_protocol Great proj...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Impresive and great project. I trust this proj...\n",
       "1  RT @cryptomanran: Elon Musks irresponsible tw...\n",
       "2  RT @Teslacryptos: Our mission is to advance hu...\n",
       "3  RT @bmurphypointman: #business #businesses #bu...\n",
       "4  RT @JuliansyahAsdar: @fire_protocol Great proj..."
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0a252d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     Impresive and great project. I trust this proj...\n",
      "1     RT @cryptomanran: Elon Musks irresponsible tw...\n",
      "2     RT @Teslacryptos: Our mission is to advance hu...\n",
      "3     RT @bmurphypointman: #business #businesses #bu...\n",
      "4     RT @JuliansyahAsdar: @fire_protocol Great proj...\n",
      "5     @CoinDCX @smtgpt @nrjkhandelwal Ticket no 4173...\n",
      "8     RT @EriBigeria: I understand for some countrie...\n",
      "9     US Congressman expresses importance of #crypto...\n",
      "11    How do we crackdown on crypto criminals before...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "testing = df1.text[:11]\n",
    "print(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9cc306ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = []\n",
    "for t in testing:\n",
    "    test_result.append(tweet_cleaner(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4b698f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['impresive and great project i trust this project can be successfully', 'rt elon musk s irresponsible tweets have caused more people to get liquidated than any other crypto event in history over', 'rt our mission is to advance humanity by solving the world s problems we want to thank our supporters and also help crypto', 'rt business businesses businessman businesswoman businessgrowth businesstools discount affiliatemarketing check m', 'rt protocol great project for crypto assets and i really like it a team spirit that works hard and good cooperatio', 'ticket no am waiting for last days for a crypto deposit of link to show up in my coindcx account how can it take so long why is no one replying to my mails tweets since last days where is my crypto deposit can someone pls reply', 'rt i understand for some countries bitcoin and crypto is still in an experimental phase but in africa and nigeria precisely', 'us congressman expresses importance of cryptowallet privacy', 'how do we crackdown on crypto criminals before it s too late listen as explores the rising world of the criminal crypto underground and how we can stop it']\n"
     ]
    }
   ],
   "source": [
    "print(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6d952da9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>impresive and great project i trust this proje...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt elon musk s irresponsible tweets have cause...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rt our mission is to advance humanity by solvi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rt business businesses businessman businesswom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt protocol great project for crypto assets an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  impresive and great project i trust this proje...\n",
       "1  rt elon musk s irresponsible tweets have cause...\n",
       "2  rt our mission is to advance humanity by solvi...\n",
       "3  rt business businesses businessman businesswom...\n",
       "4  rt protocol great project for crypto assets an..."
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_df = pd.DataFrame(test_result,columns=['text'])\n",
    "c_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "81a0f3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_df.to_csv(\"testtweet.csv\",encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c7b71a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
